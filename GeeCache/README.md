## Day1-缓存淘汰策略

### FIFO（First In First Out）-时间因素
- 创建一个队列，新增记录添加到队尾，每次内存不够时，淘汰队首
- 优点：实现简单
- 缺点：很多场景下，越早添加的记录越常被访问，导致某些记录被频繁添加、淘汰，缓存命中率低

### LFU（Least Frequently Used)-访问频率因素
- 淘汰缓存中访问频率最低的记录。需要维护一个按照访问次数排序的队列，淘汰时选择访问次数最少的即可
- 优点：缓存命中率高
- 缺点：维护每个记录的访问次数对内存的消耗很高；如果数据的访问模式发生变化，LFU 需要较长时间去适应

### LRU（Least Recently Used）-综合考虑时间与访问频率
- 维护一个队列，如果某条记录被访问，则移到队尾，队首是最近最少访问的数据，淘汰队首的记录
- 实现是通过 `Map + Double Linked List`：map 维护键值队映射关系，双向链表用于实现队列（将元素移动到队尾、在队尾新增记录、在队头删除记录）

## Day2-单机并发缓存
缓存值的存储和获取的逻辑：
```
                            是
接收 key --> 检查是否被缓存 -----> 返回缓存值 ⑴
                |  否                         是
                |-----> 是否应当从远程节点获取 -----> 与远程节点交互 --> 返回缓存值 ⑵
                            |  否
                            |-----> 调用`回调函数`，获取值并添加到缓存 --> 返回缓存值 ⑶
```

## Day3-HTTP 服务端

## Day4-一致性哈希
- 对于分布式缓存而言，如果每次都随机选取节点去获取数据，很可能导致多个节点缓存了同样的数据，并且缓存效率低（上次刚缓存的节点，并不一定下次又随机到），需要通过哈希算法，遇到相同的 key 时，去访问特定的节点
- 一个经典的哈希算法就是 `h(key) % n`，但如果节点的数量发生了改变，之前的所有缓存几乎都会失效，节点在接收到对应的请求时，均需要重新去数据源获取数据，容易引起**缓存雪崩**
  > **缓存雪崩：缓存在同一时刻全部失效，造成瞬时 DB 请求量大、压力骤增，引起雪崩。常因为缓存服务器宕机，或缓存设置了相同的过期时间引起。**
- 一致性哈希算法可以用于解决缓存雪崩的问题
  - 算法步骤：一致性哈希算法将 key 映射到 `2^32` 的空间中，将这些数字首尾相连，形成一个环
    - 计算节点/机器（通常使用节点的名称、编号和 IP 地址）的哈希值，放置在环上
    - 计算 key 的哈希值，放置在环上，顺时针寻找到的第一个节点，就是应该选取的节点/机器
  - 当新增/删除节点时，只需要重新定位该节点附近的一小部分数据，而不需要重新定位所有的节点
  - 数据倾斜：如果服务器的**节点过少**，容易引起 key 的倾斜（例如环的下半部分没有节点，那么映射到环的下半部分的 key 都会分配给第一个节点），造成缓存节点间负载不均衡
    - 解决办法：**引入虚拟节点**，一个真实节点对应多个虚拟节点，例如 `peer1` 对应三个虚拟节点 `peer1-1 peer1-2 peer1-3`
    - 第一步，计算虚拟节点的 Hash 值，放置在环上
    - 第二步，计算 key 的 Hash 值，在环上顺时针寻找到应选取的**虚拟节点**，将其分配给该虚拟节点对应的真实节点
    - 虚拟节点扩充了节点的数量，解决了节点较少的情况下数据容易倾斜的问题，代价仅仅是维护一个真实节点与虚拟节点的映射关系